{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMNIST6convlayers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLqR1dmDF+XzNrfJ0GiquM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KanishkGar/Eva/blob/main/EMNIST6convlayers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toSHmMNPYJGd"
      },
      "source": [
        "import torch\r\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "from torch.utils.data import Dataset\r\n",
        "class OHLC(Dataset):\r\n",
        "  def __init__(self, csv_file):\r\n",
        "    self.data = pd.read_csv(csv_file)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    r = self.data.iloc[index]\r\n",
        "    label = torch.tensor(r.is_up_day, dtype=torch.long)\r\n",
        "    sample = self.normalize(torch.tensor([r.open, r.high, r.low, r.close]))\r\n",
        "    return sample, label\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "Lrl5JxYSYXf1",
        "outputId": "7d5f01ac-dff5-40e3-e26b-561a7ba96a3f"
      },
      "source": [
        "train_set = torchvision.datasets.EMNIST(\r\n",
        "    root='./data'\r\n",
        "    ,train=True\r\n",
        "    ,download=True\r\n",
        "    ,transform=transforms.Compose([\r\n",
        "        transforms.ToTensor()\r\n",
        "    ])\r\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-96e2a0018e7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ,transform=transforms.Compose([\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     ])\n\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScOgD5QmHdog"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "class Network(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, padding = 1, padding_mode='replicate')\r\n",
        "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, padding = 1, padding_mode='replicate')\r\n",
        "                                                                      #\r\n",
        "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding = 1, padding_mode='replicate')\r\n",
        "        self.conv4 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, padding = 1, padding_mode='replicate')\r\n",
        "\r\n",
        "        self.conv5 = nn.Conv2d(in_channels=20, out_channels=30, kernel_size=3, padding = 1, padding_mode='replicate')\r\n",
        "        self.conv6 = nn.Conv2d(in_channels=30, out_channels=30, kernel_size=3, padding = 1, padding_mode='replicate')\r\n",
        "\r\n",
        "        self.out = nn.AvgPool2d(kernel_size= 2)\r\n",
        "        # self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\r\n",
        "        # self.fc2 = nn.Linear(in_features=120, out_features=60)\r\n",
        "        # self.out = nn.Linear(in_features=60, out_features=10)\r\n",
        "\r\n",
        "    def forward(self, t):\r\n",
        "        # implement the forward pass\r\n",
        "        # (1) input layer\r\n",
        "        t = t\r\n",
        "\r\n",
        "        # (2) hidden conv layer\r\n",
        "        t = self.conv1(t)\r\n",
        "        t = F.relu(t)\r\n",
        "\r\n",
        "        # (3) hidden conv layer\r\n",
        "        t = self.conv2(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        # (4) hidden conv layer\r\n",
        "        t = self.conv3(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        \r\n",
        "        # (5) hidden conv layer\r\n",
        "        t = self.conv4(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        # (6) hidden conv layer\r\n",
        "        t = self.conv5(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        \r\n",
        "        # (7) hidden conv layer\r\n",
        "        t = self.conv6(t)\r\n",
        "        t = F.relu(t)#not sure if this is supposed to be here\r\n",
        "        \r\n",
        "        # (8) output layer\r\n",
        "        t = self.out(t)\r\n",
        "        #t = F.softmax(t, dim=1)\r\n",
        "        return t"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txtubz7md5x8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}